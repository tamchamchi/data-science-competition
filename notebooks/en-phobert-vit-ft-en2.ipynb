{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9663489,"sourceType":"datasetVersion","datasetId":5904265},{"sourceId":9663499,"sourceType":"datasetVersion","datasetId":5904272},{"sourceId":9768674,"sourceType":"datasetVersion","datasetId":5983021},{"sourceId":9769691,"sourceType":"datasetVersion","datasetId":5983790},{"sourceId":9784517,"sourceType":"datasetVersion","datasetId":5994759},{"sourceId":9786047,"sourceType":"datasetVersion","datasetId":5995919},{"sourceId":9820939,"sourceType":"datasetVersion","datasetId":6021815},{"sourceId":9821333,"sourceType":"datasetVersion","datasetId":6022138},{"sourceId":9821493,"sourceType":"datasetVersion","datasetId":6022265},{"sourceId":9821966,"sourceType":"datasetVersion","datasetId":6022614},{"sourceId":9822378,"sourceType":"datasetVersion","datasetId":6022933}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport gc\nimport json\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms\nfrom IPython.display import clear_output\nimport pandas as pd\nimport wandb\nimport random\nimport copy\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.decomposition import PCA\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, CLIPProcessor, CLIPModel, AutoImageProcessor, AutoModel, AutoModelForCausalLM, AutoProcessor, VisionTextDualEncoderModel, VisionTextDualEncoderProcessor\nfrom transformers import ViltProcessor, ViltModel\nfrom sklearn.metrics import f1_score\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n        ","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:11.741287Z","iopub.execute_input":"2024-11-11T06:58:11.741659Z","iopub.status.idle":"2024-11-11T06:58:20.527781Z","shell.execute_reply.started":"2024-11-11T06:58:11.741616Z","shell.execute_reply":"2024-11-11T06:58:20.526880Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ndevice1 = \"cuda:1\" if torch.cuda.device_count() > 1 else \"cpu\"\n\nprint(f\"Thiết bị 0: {device}\")\nprint(f\"Thiết bị 1: {device1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:20.529615Z","iopub.execute_input":"2024-11-11T06:58:20.530210Z","iopub.status.idle":"2024-11-11T06:58:20.598328Z","shell.execute_reply.started":"2024-11-11T06:58:20.530173Z","shell.execute_reply":"2024-11-11T06:58:20.597410Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import wandb\n# run = wandb.init()\n# artifact = run.use_artifact('nguyenduytamanh03012004-uit/huggingface/fine_tune_vit5:v0', type='model')\n# artifact_dir = artifact.download()\n# run.finish()","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:20.600040Z","iopub.execute_input":"2024-11-11T06:58:20.600376Z","iopub.status.idle":"2024-11-11T06:58:20.604466Z","shell.execute_reply.started":"2024-11-11T06:58:20.600328Z","shell.execute_reply":"2024-11-11T06:58:20.603475Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # vit5_finetune-----------------------------------------------------------\n# # vit5_model = AutoModelForSeq2SeqLM.from_pretrained(artifact_dir)\n# # vit5_processor = AutoTokenizer.from_pretrained(artifact_dir)\n# # vit5 -------------------------------------------------------------------\n# vit5_model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base\")\n# vit5_processor = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\n# #clip ---------------------------------------------------------------------\n# image_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n# clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n\n# vilt_processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\")\n# vilt_model = ViltModel.from_pretrained(\"dandelin/vilt-b32-mlm\")\n# # #dino --------------------------------------------------------------------\n# # dino_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n# # dino_model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)\n# # visocial_T5_fintune -------------------------------------------------------\n# # visocial_processor = AutoTokenizer.from_pretrained(\"5CD-AI/visocial-T5-base\")\n# # visocial_model = AutoModelForSeq2SeqLM.from_pretrained(artifact_dir).to(device)\n# # llava---------------------------------------------------------------------------\n# # llava_model = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n# # llava_processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n# # vilt\n\n# # bert & vit\n# # bert_tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n# # vit_image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n# # processor = VisionTextDualEncoderProcessor(vit_image_processor, bert_tokenizer)\n# # model = VisionTextDualEncoderModel.from_vision_text_pretrained(\n# #     \"google/vit-base-patch16-224\", \"google-bert/bert-base-uncased\"\n# # )\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:20.606085Z","iopub.execute_input":"2024-11-11T06:58:20.606564Z","iopub.status.idle":"2024-11-11T06:58:20.616024Z","shell.execute_reply.started":"2024-11-11T06:58:20.606513Z","shell.execute_reply":"2024-11-11T06:58:20.615018Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đường dẫn đến thư mục chứa ảnh\nimage_train_dir = '/kaggle/input/dsc-dataset/train-images/train-images' \nimage_test_dir = '/kaggle/input/dsc-dataset/dev-images/dev-images'\n\n# Lấy danh sách các tệp ảnh .jpg\nimage_train_paths = [os.path.join(image_train_dir, file) for file in os.listdir(image_train_dir) if file.endswith('.jpg')]\nimage_test_paths = [os.path.join(image_test_dir, file) for file in os.listdir(image_test_dir) if file.endswith('.jpg')]\n\n# Đọc dữ liệu từ file JSON\nwith open('/kaggle/input/data-demoji-remove-hashtag-url-v3/processed_train_demoji_remove_hashtag_url_v3.json', 'r', encoding='utf-8') as f:\n    data_train = json.load(f)\n\nwith open('/kaggle/input/data-demoji-remove-hashtag-url-v3/processed_pred_demoji_remove_hashtag_url_v3.json', 'r', encoding='utf-8') as f:\n    data_test = json.load(f)\n    \n\ncombined_data_train = []\ncombined_data_test = []\n\nlabel_mapping = {\n    \"not-sarcasm\": 0,\n    \"text-sarcasm\": 1,\n    \"image-sarcasm\": 2,\n    \"multi-sarcasm\": 3,\n}\n\n# Khởi tạo biến id để đếm số lượng mục\ntrain_id = 0\ntest_id = 0\n\n# Duyệt qua từng mục trong dữ liệu JSON để tạo combined_data_train\nfor key, value in data_train.items():\n    image_name = value[\"image\"]\n    image_path = os.path.join(image_train_dir, image_name)  # Tạo đường dẫn tuyệt đối cho từng hình ảnh\n    \n    # Kiểm tra xem ảnh có trong danh sách hay không\n    if image_path in image_train_paths:\n        label = value.get(\"label\")  # Lấy giá trị label\n        if label is not None and label in label_mapping:  # Kiểm tra giá trị label\n            combined_data_train.append({\n                'id': train_id,  # Thêm id theo thứ tự\n                'image': image_path,  # Lưu đường dẫn tuyệt đối\n                'caption': value[\"caption\"],\n                'label': label_mapping[label],  # Lưu label từ label_mapping\\\n#                 'text_image': value[\"text_image\"]\n            })\n            train_id += 1  # Tăng id sau mỗi lần thêm\n\n# Duyệt qua từng mục trong dữ liệu JSON để tạo combined_data_test\nfor key, value in data_test.items():\n    image_name = value[\"image\"]\n    image_path = os.path.join(image_test_dir, image_name)  # Tạo đường dẫn tuyệt đối cho từng hình ảnh\n\n    # Kiểm tra xem ảnh có trong danh sách hay không\n    if image_path in image_test_paths:\n        combined_data_test.append({\n            'id': test_id,  # Thêm id theo thứ tự\n            'image': image_path,  # Lưu đường dẫn tuyệt đối\n            'caption': value[\"caption\"],\n            'label': value[\"label\"],  # Lưu label từ label_mapping\n#             'text_image': value[\"text_image\"]\n        })\n        test_id += 1  # Tăng id sau mỗi lần thêm\n\n# In ra kết quả\n# print(combined_data_train)\n# print(combined_data_test)\n\n# Tách caption và label từ combined_data_train\ntexts_train = [item['caption'] for item in combined_data_train]\nlabels_train = [item['label'] for item in combined_data_train]\nid_train = [item['id'] for item in combined_data_train]\nimages_train = [item['image'] for item in combined_data_train]\n# text_images_train = [item['text_image'] for item in combined_data_train]\ntexts_test = [item['caption'] for item in combined_data_test]\nlabels_test = [item['label'] for item in combined_data_test]\nid_test = [item['id'] for item in combined_data_test]\nimages_test = [item['image'] for item in combined_data_test]\n# text_image_test = [item['text_image'] for item in combined_data_test]\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:20.618812Z","iopub.execute_input":"2024-11-11T06:58:20.619135Z","iopub.status.idle":"2024-11-11T06:58:22.513381Z","shell.execute_reply.started":"2024-11-11T06:58:20.619099Z","shell.execute_reply":"2024-11-11T06:58:22.512543Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\n# Chia dữ liệu thành train và validation với tỷ lệ 80-20\ntexts_train, texts_val, labels_train, labels_val, id_train, id_val, images_train, images_val = train_test_split(\n    texts_train, labels_train, id_train, images_train, test_size=0.2, random_state=42)\n\n# In kết quả để kiểm tra\nprint(f\"Số lượng dữ liệu train: {len(texts_train)}\")\nprint(f\"Số lượng dữ liệu validation: {len(texts_val)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:22.514535Z","iopub.execute_input":"2024-11-11T06:58:22.514855Z","iopub.status.idle":"2024-11-11T06:58:22.533968Z","shell.execute_reply.started":"2024-11-11T06:58:22.514820Z","shell.execute_reply":"2024-11-11T06:58:22.532985Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install open_clip_torch\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:22.535562Z","iopub.execute_input":"2024-11-11T06:58:22.536277Z","iopub.status.idle":"2024-11-11T06:58:34.679786Z","shell.execute_reply.started":"2024-11-11T06:58:22.536223Z","shell.execute_reply":"2024-11-11T06:58:34.678762Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport open_clip\nimport requests\nfrom PIL import Image\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:34.681470Z","iopub.execute_input":"2024-11-11T06:58:34.681906Z","iopub.status.idle":"2024-11-11T06:58:35.131029Z","shell.execute_reply.started":"2024-11-11T06:58:34.681855Z","shell.execute_reply":"2024-11-11T06:58:35.129911Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer, CLIPProcessor, CLIPModel\nfrom transformers import ViTImageProcessor, ViTForImageClassification\nfrom PIL import Image\nimport requests\n\n# 1. Khởi tạo mô hình\nphobert_model_name = \"vinai/phobert-base-v2\"\nimage_model_name = \"google/vit-base-patch16-224\"\n\nphobert_tokenizer = AutoTokenizer.from_pretrained(phobert_model_name)\nphobert_model = AutoModel.from_pretrained(phobert_model_name)\n\nimage_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\nimage_model =ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:35.132339Z","iopub.execute_input":"2024-11-11T06:58:35.132704Z","iopub.status.idle":"2024-11-11T06:58:36.886836Z","shell.execute_reply.started":"2024-11-11T06:58:35.132669Z","shell.execute_reply":"2024-11-11T06:58:36.885084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # vit_image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n# # processor = VisionTextDualEncoderProcessor(vit_image_processor, bert_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:36.888804Z","iopub.execute_input":"2024-11-11T06:58:36.889229Z","iopub.status.idle":"2024-11-11T06:58:36.893822Z","shell.execute_reply.started":"2024-11-11T06:58:36.889180Z","shell.execute_reply":"2024-11-11T06:58:36.892834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_text(texts, tokenizer):\n\n  inputs = tokenizer(\n      texts,\n      return_tensors=\"pt\",\n      padding=True,\n      truncation=True,\n      max_length=256  # Điều chỉnh max_length nếu cần\n  )\n  return inputs.input_ids, inputs.attention_mask","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:36.895094Z","iopub.execute_input":"2024-11-11T06:58:36.895515Z","iopub.status.idle":"2024-11-11T06:58:36.904553Z","shell.execute_reply.started":"2024-11-11T06:58:36.895476Z","shell.execute_reply":"2024-11-11T06:58:36.903682Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_image(image_paths, processor):\n\n    images = [Image.open(path).convert(\"RGB\") for path in image_paths]\n    images = [image.resize((224, 224)) for image in images]\n    inputs = processor(\n    images=images,\n    return_tensors=\"pt\",\n    )\n    return inputs.pixel_values","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:36.905606Z","iopub.execute_input":"2024-11-11T06:58:36.905886Z","iopub.status.idle":"2024-11-11T06:58:36.915908Z","shell.execute_reply.started":"2024-11-11T06:58:36.905855Z","shell.execute_reply":"2024-11-11T06:58:36.914867Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CustomDataset(Dataset):\n  def __init__(self, input_ids, attention_mask, pixel_values, labels):\n    self.input_ids = input_ids\n    self.attention_mask = attention_mask\n    self.pixel_values = pixel_values\n    self.labels = labels\n\n  def __len__(self):\n    return len(self.labels)\n\n  def __getitem__(self, idx):\n    return {\n        \"input_ids\": self.input_ids[idx],\n        \"attention_mask\": self.attention_mask[idx],\n        \"pixel_values\": self.pixel_values[idx],\n        \"labels\": self.labels[idx]\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:36.917055Z","iopub.execute_input":"2024-11-11T06:58:36.917391Z","iopub.status.idle":"2024-11-11T06:58:36.926617Z","shell.execute_reply.started":"2024-11-11T06:58:36.917343Z","shell.execute_reply":"2024-11-11T06:58:36.925838Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Xử lý dữ liệu train\ntrain_pixel_values = preprocess_image(images_train, image_processor)\ntrain_input_ids, train_attention_mask = preprocess_text(texts_train, phobert_tokenizer)\n\n# Xử lý dữ liệu val\nval_input_ids, val_attention_mask = preprocess_text(texts_val, phobert_tokenizer)\nval_pixel_values = preprocess_image(images_val, image_processor)\n\n# Tạo DataLoader\ntrain_dataset = CustomDataset(train_input_ids, train_attention_mask, train_pixel_values, labels_train)\nval_dataset = CustomDataset(val_input_ids, val_attention_mask, val_pixel_values, labels_val)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:36.930880Z","iopub.execute_input":"2024-11-11T06:58:36.931202Z","iopub.status.idle":"2024-11-11T06:58:36.943298Z","shell.execute_reply.started":"2024-11-11T06:58:36.931168Z","shell.execute_reply":"2024-11-11T06:58:36.942438Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lưu dữ liệu train\ntorch.save({\n    'input_ids': train_input_ids,\n    'attention_mask': train_attention_mask,\n    'pixel_values': train_pixel_values,\n    'labels': labels_train\n}, 'train_data.pt')\n\n# Lưu dữ liệu val\ntorch.save({\n    'input_ids': val_input_ids,\n    'attention_mask': val_attention_mask,\n    'pixel_values': val_pixel_values,\n    'labels': labels_val\n}, 'val_data.pt')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:36.944546Z","iopub.execute_input":"2024-11-11T06:58:36.944917Z","iopub.status.idle":"2024-11-11T06:58:36.953705Z","shell.execute_reply.started":"2024-11-11T06:58:36.944881Z","shell.execute_reply":"2024-11-11T06:58:36.952725Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tải dữ liệu train\ntrain_data = torch.load('train_data.pt')\ntrain_dataset = CustomDataset(\n    train_data['input_ids'],\n    train_data['attention_mask'],\n    train_data['pixel_values'],\n    train_data['labels']\n)\n\n# Tải dữ liệu val\nval_data = torch.load('val_data.pt')\nval_dataset = CustomDataset(\n    val_data['input_ids'],\n    val_data['attention_mask'],\n    val_data['pixel_values'],\n    val_data['labels']\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:36.955264Z","iopub.execute_input":"2024-11-11T06:58:36.955844Z","iopub.status.idle":"2024-11-11T06:58:43.657600Z","shell.execute_reply.started":"2024-11-11T06:58:36.955792Z","shell.execute_reply":"2024-11-11T06:58:43.656648Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True ,num_workers = 4)  # Điều chỉnh batch_size nếu cần\nval_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, pin_memory=True ,num_workers = 4)","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:43.658952Z","iopub.execute_input":"2024-11-11T06:58:43.659468Z","iopub.status.idle":"2024-11-11T06:58:43.665204Z","shell.execute_reply.started":"2024-11-11T06:58:43.659410Z","shell.execute_reply":"2024-11-11T06:58:43.664183Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(train_dataloader))","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:43.666941Z","iopub.execute_input":"2024-11-11T06:58:43.667410Z","iopub.status.idle":"2024-11-11T06:58:43.681576Z","shell.execute_reply.started":"2024-11-11T06:58:43.667341Z","shell.execute_reply":"2024-11-11T06:58:43.680628Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(set(labels_train)))","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:43.682803Z","iopub.execute_input":"2024-11-11T06:58:43.683115Z","iopub.status.idle":"2024-11-11T06:58:43.690979Z","shell.execute_reply.started":"2024-11-11T06:58:43.683081Z","shell.execute_reply":"2024-11-11T06:58:43.689964Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class EnsembleModel(nn.Module):\n#     def __init__(self, phobert_model, image_model, num_classes):\n#         super(EnsembleModel, self).__init__()\n#         self.phobert_model = phobert_model\n#         self.image_model = image_model\n#         self.classifier = nn.Linear(\n#             phobert_model.config.hidden_size + image_model.config.hidden_size, num_classes\n#         )\n\n#     def forward(self, input_ids, attention_mask, pixel_values):\n#         # Lấy output từ PhoBERT\n#         phobert_output = self.phobert_model(input_ids=input_ids, attention_mask=attention_mask)\n#         phobert_features = phobert_output.last_hidden_state[:, 0, :]  # Đặc trưng của token [CLS]\n        \n#         # Lấy output từ ViT, yêu cầu output_hidden_states=True để lấy hidden states của lớp cuối\n#         image_output = self.image_model(pixel_values=pixel_values, output_hidden_states=True)\n#         image_features = image_output.hidden_states[-1][:, 0, :]  # Đặc trưng của token [CLS] từ lớp cuối\n        \n#         # Nối các đặc trưng từ PhoBERT và ViT\n#         combined_features = torch.cat((phobert_features, image_features), dim=1)\n#         logits = self.classifier(combined_features)\n        \n#         return logits\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:43.692008Z","iopub.execute_input":"2024-11-11T06:58:43.692311Z","iopub.status.idle":"2024-11-11T06:58:43.700963Z","shell.execute_reply.started":"2024-11-11T06:58:43.692279Z","shell.execute_reply":"2024-11-11T06:58:43.700115Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass EnsembleModel(nn.Module):\n    def __init__(self, phobert_model, image_model, num_classes, dropout_rate=0.3):\n        super(EnsembleModel, self).__init__()\n        self.phobert_model = phobert_model\n        self.image_model = image_model\n        \n        # Thêm lớp Dropout để giảm overfitting\n        self.dropout = nn.Dropout(dropout_rate)\n        \n        # Lớp phân loại\n        self.classifier = nn.Linear(\n            phobert_model.config.hidden_size + image_model.config.hidden_size, num_classes\n        )\n\n    def forward(self, input_ids, attention_mask, pixel_values):\n        # Lấy output từ PhoBERT\n        phobert_output = self.phobert_model(input_ids=input_ids, attention_mask=attention_mask)\n        phobert_features = phobert_output.last_hidden_state[:, 0, :]  # Đặc trưng của token [CLS]\n        \n        # Lấy output từ ViT, yêu cầu output_hidden_states=True để lấy hidden states của lớp cuối\n        image_output = self.image_model(pixel_values=pixel_values, output_hidden_states=True)\n        image_features = image_output.hidden_states[-1][:, 0, :]  # Đặc trưng của token [CLS] từ lớp cuối\n        \n        # Nối các đặc trưng từ PhoBERT và ViT\n        combined_features = torch.cat((phobert_features, image_features), dim=1)\n        \n        # Áp dụng dropout để ngăn overfitting\n        combined_features = self.dropout(combined_features)\n        \n        # Phân loại\n        logits = self.classifier(combined_features)\n        \n        return logits\n\n\n\n# Hàm huấn luyện và đánh giá sử dụng mô hình này\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:43.702053Z","iopub.execute_input":"2024-11-11T06:58:43.702342Z","iopub.status.idle":"2024-11-11T06:58:43.713258Z","shell.execute_reply.started":"2024-11-11T06:58:43.702310Z","shell.execute_reply":"2024-11-11T06:58:43.712400Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sử dụng Focal Loss để giảm ảnh hưởng của mất cân bằng lớp\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n        return F_loss","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:43.714250Z","iopub.execute_input":"2024-11-11T06:58:43.714550Z","iopub.status.idle":"2024-11-11T06:58:43.726816Z","shell.execute_reply.started":"2024-11-11T06:58:43.714518Z","shell.execute_reply":"2024-11-11T06:58:43.726020Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Khởi tạo optimizer với weight decay mạnh hơn và cosine annealing\ndef get_optimizer_with_regularization(model, base_learning_rate=1e-5, weight_decay=1e-3, T_0=5, T_mult=2):\n    optimizer = optim.AdamW(\n        model.parameters(),\n        lr=base_learning_rate,\n        weight_decay=weight_decay\n    )\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=T_mult)\n    return optimizer, scheduler\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:43.727973Z","iopub.execute_input":"2024-11-11T06:58:43.728756Z","iopub.status.idle":"2024-11-11T06:58:43.739605Z","shell.execute_reply.started":"2024-11-11T06:58:43.728711Z","shell.execute_reply":"2024-11-11T06:58:43.738740Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(set(labels_train))  # Đảm bảo số lớp của mô hình khớp với số lớp của nhãn\n\nphobert_model = phobert_model.to(device)\nimage_model = image_model.to(device)\nmodel = EnsembleModel(phobert_model, image_model, num_classes, dropout_rate=0.5).to(device)\n# Ví dụ sử dụng model\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:43.740701Z","iopub.execute_input":"2024-11-11T06:58:43.741061Z","iopub.status.idle":"2024-11-11T06:58:44.166805Z","shell.execute_reply.started":"2024-11-11T06:58:43.741018Z","shell.execute_reply":"2024-11-11T06:58:44.165755Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Xác định số lượng lớp trong mô hình PhoBERT và ViT\nphobert_num_layers = len(model.phobert_model.encoder.layer)\nimage_num_layers = len(model.image_model.vit.encoder.layer)  # Truy cập vào transformer layers của ViT\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:44.168083Z","iopub.execute_input":"2024-11-11T06:58:44.168471Z","iopub.status.idle":"2024-11-11T06:58:44.173755Z","shell.execute_reply.started":"2024-11-11T06:58:44.168416Z","shell.execute_reply":"2024-11-11T06:58:44.172764Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(phobert_num_layers)\nprint(image_num_layers)","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:44.175131Z","iopub.execute_input":"2024-11-11T06:58:44.175672Z","iopub.status.idle":"2024-11-11T06:58:44.185605Z","shell.execute_reply.started":"2024-11-11T06:58:44.175616Z","shell.execute_reply":"2024-11-11T06:58:44.184603Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tinh chỉnh nửa số lớp cuối của PhoBERT\nfor param in model.phobert_model.parameters():\n    param.requires_grad = False  # Đóng băng tất cả các lớp\nfor layer in model.phobert_model.encoder.layer[-(phobert_num_layers // 2):]:  # Tinh chỉnh nửa số lớp cuối\n    for param in layer.parameters():\n        param.requires_grad = True\n\n# Tinh chỉnh nửa số lớp cuối của CLIP\nfor param in model.image_model.parameters():\n    param.requires_grad = False  # Đóng băng tất cả các lớp\nfor layer in model.image_model.vit.encoder.layer[-(image_num_layers // 2):]:  # Tinh chỉnh nửa số lớp cuối\n    for param in layer.parameters():\n        param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:44.186629Z","iopub.execute_input":"2024-11-11T06:58:44.186890Z","iopub.status.idle":"2024-11-11T06:58:44.199731Z","shell.execute_reply.started":"2024-11-11T06:58:44.186860Z","shell.execute_reply":"2024-11-11T06:58:44.198759Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Kiểm tra xem các tham số của mô hình có gradient hay không\n# for name, param in model.named_parameters():\n#     if param.requires_grad:\n#         print(f\"Tham số {name} có gradient và sẽ được tinh chỉnh.\")\n#     else:\n#         print(f\"Tham số {name} không có gradient và sẽ không được tinh chỉnh.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:44.200908Z","iopub.execute_input":"2024-11-11T06:58:44.201267Z","iopub.status.idle":"2024-11-11T06:58:44.213867Z","shell.execute_reply.started":"2024-11-11T06:58:44.201225Z","shell.execute_reply":"2024-11-11T06:58:44.213021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pre_training_params = {name: param.detach().clone() for name, param in model.named_parameters()}\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T06:58:44.214970Z","iopub.execute_input":"2024-11-11T06:58:44.215261Z","iopub.status.idle":"2024-11-11T06:58:44.224410Z","shell.execute_reply.started":"2024-11-11T06:58:44.215230Z","shell.execute_reply":"2024-11-11T06:58:44.223559Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Thêm thư viện để theo dõi tiến trình\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score\n\n\n# Huấn luyện mô hình\nnum_epochs = 15  # Điều chỉnh số lượng epochs\nearly_stopping_patience = 3  # Số epoch không cải thiện trước khi dừng sớm\nbest_val_loss = float('inf')\nepochs_no_improve = 0\n\n# Chuyển các mô hình vào chế độ huấn luyện\nmodel.train()\nphobert_model.train()\nimage_model.train()\n\nimport torch.optim as optim\n\n\n# Xác định hàm mất mát và bộ tối ưu\noptimizer, scheduler = get_optimizer_with_regularization(model)\n\nfor epoch in range(num_epochs):\n    # Biến để tính toán loss và accuracy của tập train\n    train_loss = 0.0\n    train_preds = []\n    train_labels = []\n    \n    # Theo dõi tiến trình từng batch với tqdm\n    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        pixel_values = batch[\"pixel_values\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        # Lan truyền thuận và ngược\n        outputs = model(input_ids, attention_mask, pixel_values)\n        loss = FocalLoss()(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Cộng dồn loss\n        train_loss += loss.item()\n        _, preds = torch.max(outputs, dim=1)\n        train_preds.extend(preds.cpu().numpy())\n        train_labels.extend(labels.cpu().numpy())\n\n        del input_ids, attention_mask, pixel_values, labels, outputs, loss\n        torch.cuda.empty_cache()\n\n    # Tính toán metrics cho epoch\n    train_accuracy = accuracy_score(train_labels, train_preds)\n    val_loss = 0.0\n    val_preds = []\n    val_labels = []\n    \n    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n    with torch.no_grad():\n        for batch in tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            pixel_values = batch[\"pixel_values\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            outputs = model(input_ids, attention_mask, pixel_values)\n            loss = FocalLoss()(outputs, labels)\n            val_loss += loss.item()\n\n            _, preds = torch.max(outputs, dim=1)\n            val_preds.extend(preds.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n\n            del input_ids, attention_mask, pixel_values, labels, outputs, loss\n            torch.cuda.empty_cache()\n\n    val_accuracy = accuracy_score(val_labels, val_preds)\n    val_f1_macro = f1_score(val_labels, val_preds, average='macro')\n    \n    print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n    print(f\"  Train Loss: {train_loss/len(train_dataloader):.4f}\")\n    print(f\"  Train Accuracy: {train_accuracy:.4f}\")\n    print(f\"  Validation Loss: {val_loss/len(val_dataloader):.4f}\")\n    print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n    print(f\"  Validation F1 Score (Macro): {val_f1_macro:.4f}\")\n\n    # Lưu checkpoint và kiểm tra Early Stopping\n    checkpoint = {\n        'epoch': epoch + 1,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'train_loss': train_loss / len(train_dataloader),\n        'train_accuracy': train_accuracy,\n        'val_loss': val_loss / len(val_dataloader),\n        'val_accuracy': val_accuracy,\n        'val_f1_macro': val_f1_macro,\n    }\n    \n    checkpoint_path = f\"checkpoint_epoch_{epoch+1}.pth\"\n    torch.save(checkpoint, checkpoint_path)\n    print(f\"Checkpoint saved to {checkpoint_path}\")\n    \n    # Kiểm tra điều kiện dừng sớm (Early Stopping)\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        epochs_no_improve = 0\n    else:\n        epochs_no_improve += 1\n        if epochs_no_improve >= early_stopping_patience:\n            print(\"Stopping early due to no improvement in validation loss.\")\n            break\n\n    model.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T07:04:33.105258Z","iopub.execute_input":"2024-11-11T07:04:33.105700Z","iopub.status.idle":"2024-11-11T07:34:42.308347Z","shell.execute_reply.started":"2024-11-11T07:04:33.105650Z","shell.execute_reply":"2024-11-11T07:34:42.307117Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# for epoch in range(3):\n#     # Biến để tính toán loss và accuracy của tập train\n#     train_loss = 0.0\n#     train_preds = []\n#     train_labels = []\n    \n#     # Theo dõi tiến trình từng batch với tqdm\n#     for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n#         input_ids = batch[\"input_ids\"].to(device)\n#         attention_mask = batch[\"attention_mask\"].to(device)\n#         pixel_values = batch[\"pixel_values\"].to(device)\n#         labels = batch[\"labels\"].to(device)\n\n#         # Lan truyền thuận và ngược\n#         outputs = model(input_ids, attention_mask, pixel_values)\n#         loss = criterion(outputs, labels)\n\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#         # Cộng dồn loss\n#         train_loss += loss.item()\n#         _, preds = torch.max(outputs, dim=1)\n#         train_preds.extend(preds.cpu().numpy())\n#         train_labels.extend(labels.cpu().numpy())\n\n#         del input_ids, attention_mask, pixel_values, labels, outputs, loss\n#         torch.cuda.empty_cache()\n\n#     # Tính toán metrics cho epoch\n#     train_accuracy = accuracy_score(train_labels, train_preds)\n#     val_loss = 0.0\n#     val_preds = []\n#     val_labels = []\n    \n#     model.eval()  # Chuyển mô hình sang chế độ đánh giá\n#     with torch.no_grad():\n#         for batch in tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n#             input_ids = batch[\"input_ids\"].to(device)\n#             attention_mask = batch[\"attention_mask\"].to(device)\n#             pixel_values = batch[\"pixel_values\"].to(device)\n#             labels = batch[\"labels\"].to(device)\n\n#             outputs = model(input_ids, attention_mask, pixel_values)\n#             loss = criterion(outputs, labels)\n#             val_loss += loss.item()\n\n#             _, preds = torch.max(outputs, dim=1)\n#             val_preds.extend(preds.cpu().numpy())\n#             val_labels.extend(labels.cpu().numpy())\n\n#             del input_ids, attention_mask, pixel_values, labels, outputs, loss\n#             torch.cuda.empty_cache()\n\n#     val_accuracy = accuracy_score(val_labels, val_preds)\n#     val_f1_macro = f1_score(val_labels, val_preds, average='macro')\n    \n#     print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n#     print(f\"  Train Loss: {train_loss/len(train_dataloader):.4f}\")\n#     print(f\"  Train Accuracy: {train_accuracy:.4f}\")\n#     print(f\"  Validation Loss: {val_loss/len(val_dataloader):.4f}\")\n#     print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n#     print(f\"  Validation F1 Score (Macro): {val_f1_macro:.4f}\")\n\n#     # Lưu checkpoint và kiểm tra Early Stopping\n#     checkpoint = {\n#         'epoch': epoch + 1,\n#         'model_state_dict': model.state_dict(),\n#         'optimizer_state_dict': optimizer.state_dict(),\n#         'train_loss': train_loss / len(train_dataloader),\n#         'train_accuracy': train_accuracy,\n#         'val_loss': val_loss / len(val_dataloader),\n#         'val_accuracy': val_accuracy,\n#         'val_f1_macro': val_f1_macro,\n#     }\n    \n#     checkpoint_path = f\"checkpoint_epoch_{epoch+1}.pth\"\n#     torch.save(checkpoint, checkpoint_path)\n#     print(f\"Checkpoint saved to {checkpoint_path}\")\n    \n#     # Kiểm tra điều kiện dừng sớm (Early Stopping)\n#     if val_loss < best_val_loss:\n#         best_val_loss = val_loss\n#         epochs_no_improve = 0\n#     else:\n#         epochs_no_improve += 1\n#         if epochs_no_improve >= early_stopping_patience:\n#             print(\"Stopping early due to no improvement in validation loss.\")\n#             break\n\n#     model.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T07:03:13.343967Z","iopub.status.idle":"2024-11-11T07:03:13.344491Z","shell.execute_reply.started":"2024-11-11T07:03:13.344206Z","shell.execute_reply":"2024-11-11T07:03:13.344233Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import classification_report\nfrom torch.utils.data import DataLoader\n\n# Đảm bảo mô hình đang ở chế độ đánh giá (evaluation mode)\nmodel.eval()\n\n# Tạo DataLoader cho tập validation\n# val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Biến lưu trữ nhãn thực tế và dự đoán\nall_labels = []\nall_preds = []\n\n# Không tính gradient khi đánh giá\nwith torch.no_grad():\n    for batch in val_dataloader:\n        # Lấy dữ liệu và chuyển sang GPU nếu có\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        pixel_values = batch['pixel_values'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Tiến hành dự đoán\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values)\n        \n        # Kiểm tra đầu ra để lấy logits\n        if isinstance(outputs, tuple):\n            logits = outputs[0]  # Trường hợp mô hình trả về một tuple (logits, các giá trị khác)\n        else:\n            logits = outputs  # Trường hợp mô hình chỉ trả về logits\n\n        # Chuyển logits thành dự đoán (giả sử sử dụng softmax để lấy xác suất, sau đó chọn lớp có xác suất cao nhất)\n        preds = torch.argmax(logits, dim=-1)\n        \n        # Lưu trữ kết quả\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(preds.cpu().numpy())\n\n# In ra Classification Report\nreport = classification_report(all_labels, all_preds, target_names=['not-sarcasm', 'text-sarcasm', 'image-sarcasm', 'multi-sarcasm'])\nprint(\"Classification Report:\\n\", report)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T07:35:35.086956Z","iopub.execute_input":"2024-11-11T07:35:35.087920Z","iopub.status.idle":"2024-11-11T07:36:03.266705Z","shell.execute_reply.started":"2024-11-11T07:35:35.087871Z","shell.execute_reply":"2024-11-11T07:36:03.265533Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch\n\n# # Đường dẫn đến checkpoint\n# checkpoint_path = '/kaggle/working/checkpoint_epoch_5.pth'\n\n# # Tải checkpoint từ file\n# checkpoint = torch.load(checkpoint_path)\n\n# # Lấy trạng thái mô hình và các tham số huấn luyện tại epoch 5\n# epoch = checkpoint['epoch']\n# model_state_dict = checkpoint['model_state_dict']\n# optimizer_state_dict = checkpoint['optimizer_state_dict']\n# train_loss = checkpoint['train_loss']\n# train_accuracy = checkpoint['train_accuracy']\n# val_loss = checkpoint['val_loss']\n# val_accuracy = checkpoint['val_accuracy']\n# val_f1_macro = checkpoint['val_f1_macro']\n\n# # In ra thông tin tại epoch 5\n# print(f\"Epoch: {epoch}\")\n# print(f\"Train Loss: {train_loss}\")\n# print(f\"Train Accuracy: {train_accuracy}\")\n# print(f\"Validation Loss: {val_loss}\")\n# print(f\"Validation Accuracy: {val_accuracy}\")\n# print(f\"Validation F1 Score (Macro): {val_f1_macro}\")\n\n# # Khôi phục trạng thái mô hình và optimizer\n# model.load_state_dict(model_state_dict)\n# optimizer.load_state_dict(optimizer_state_dict)\n\n# # Tiếp tục huấn luyện hoặc thực hiện các tác vụ khác\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T07:03:13.349289Z","iopub.status.idle":"2024-11-11T07:03:13.349825Z","shell.execute_reply.started":"2024-11-11T07:03:13.349564Z","shell.execute_reply":"2024-11-11T07:03:13.349590Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch\n# from sklearn.metrics import classification_report\n# from torch.utils.data import DataLoader\n\n# # Đảm bảo mô hình đang ở chế độ đánh giá (evaluation mode)\n# model.eval()\n\n# # Tạo DataLoader cho tập validation\n# # val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# # Biến lưu trữ nhãn thực tế và dự đoán\n# all_labels = []\n# all_preds = []\n\n# # Không tính gradient khi đánh giá\n# with torch.no_grad():\n#     for batch in val_dataloader:\n#         # Lấy dữ liệu và chuyển sang GPU nếu có\n#         input_ids = batch['input_ids'].to(device)\n#         attention_mask = batch['attention_mask'].to(device)\n#         pixel_values = batch['pixel_values'].to(device)\n#         labels = batch['labels'].to(device)\n\n#         # Tiến hành dự đoán\n#         outputs = model(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values)\n        \n#         # Kiểm tra đầu ra để lấy logits\n#         if isinstance(outputs, tuple):\n#             logits = outputs[0]  # Trường hợp mô hình trả về một tuple (logits, các giá trị khác)\n#         else:\n#             logits = outputs  # Trường hợp mô hình chỉ trả về logits\n\n#         # Chuyển logits thành dự đoán (giả sử sử dụng softmax để lấy xác suất, sau đó chọn lớp có xác suất cao nhất)\n#         preds = torch.argmax(logits, dim=-1)\n        \n#         # Lưu trữ kết quả\n#         all_labels.extend(labels.cpu().numpy())\n#         all_preds.extend(preds.cpu().numpy())\n\n# # In ra Classification Report\n# report = classification_report(all_labels, all_preds, target_names=['not-sarcasm', 'text-sarcasm', 'image-sarcasm', 'multi-sarcasm'])\n# print(\"Classification Report:\\n\", report)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T07:03:13.351104Z","iopub.status.idle":"2024-11-11T07:03:13.351633Z","shell.execute_reply.started":"2024-11-11T07:03:13.351334Z","shell.execute_reply":"2024-11-11T07:03:13.351384Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}